"""
{{GRAPH_NAME}} - Human-in-the-Loop Workflow

Purpose: {{GRAPH_PURPOSE}}
Author: {{AUTHOR}}
Date: {{DATE}}

Axiom Alignment:
- A2 (User Primacy): Human approval required for consequential actions
- A3 (Transparency): Approval requests are explicit
"""

from typing import TypedDict, Annotated, Literal, Optional, List
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class {{GRAPH_CLASS_NAME}}State(TypedDict):
    """
    State for human-in-the-loop workflow.
    
    Attributes:
        messages: Conversation messages
        input: Original user input
        proposal: Proposed action/output
        human_feedback: Human approval/rejection
        approved: Whether proposal is approved
        final_output: Final approved output
        status: Workflow status
    """
    messages: Annotated[List[BaseMessage], add_messages]
    input: str
    proposal: Optional[str]
    human_feedback: Optional[str]
    approved: bool
    final_output: Optional[str]
    status: Literal["proposing", "awaiting_approval", "approved", "rejected", "completed"]


class {{GRAPH_CLASS_NAME}}:
    """
    {{GRAPH_NAME}} - Human-in-the-Loop Workflow
    
    Implements workflow that:
    1. Generates a proposal
    2. Requests human approval
    3. Incorporates feedback
    4. Produces final output
    
    Example:
        >>> workflow = {{GRAPH_CLASS_NAME}}()
        >>> result = workflow.run("Generate a report")
        >>> if result["status"] == "awaiting_approval":
        >>>     workflow.approve(result["proposal"])
    """
    
    def __init__(
        self,
        model_name: str = "{{MODEL_NAME}}",
        temperature: float = {{TEMPERATURE}},
        auto_approve: bool = False  # For testing
    ):
        """
        Initialize human-in-the-loop workflow.
        
        Args:
            model_name: LLM model identifier
            temperature: Sampling temperature
            auto_approve: Auto-approve proposals (for testing)
        """
        self.model_name = model_name
        self.temperature = temperature
        self.auto_approve = auto_approve
        
        # Initialize LLM
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=temperature
        )
        
        # Build graph
        self.graph = self._build_graph()
        self.app = self.graph.compile(checkpointer=MemorySaver())
        
        logger.info(f"Initialized {{GRAPH_NAME}} workflow")
    
    def _build_graph(self) -> StateGraph:
        """Build the human-in-the-loop graph."""
        graph = StateGraph({{GRAPH_CLASS_NAME}}State)
        
        # Add nodes
        graph.add_node("generate_proposal", self._generate_proposal_node)
        graph.add_node("request_approval", self._request_approval_node)
        graph.add_node("incorporate_feedback", self._incorporate_feedback_node)
        graph.add_node("finalize", self._finalize_node)
        
        # Add edges
        graph.add_edge(START, "generate_proposal")
        
        # Conditional routing
        graph.add_conditional_edges(
            "generate_proposal",
            self._route_after_proposal,
            {
                "request_approval": "request_approval",
                "finalize": "finalize"
            }
        )
        
        graph.add_conditional_edges(
            "request_approval",
            self._route_after_approval,
            {
                "incorporate_feedback": "incorporate_feedback",
                "finalize": "finalize"
            }
        )
        
        graph.add_edge("incorporate_feedback", "request_approval")
        graph.add_edge("finalize", END)
        
        return graph
    
    def _generate_proposal_node(self, state: {{GRAPH_CLASS_NAME}}State) -> dict:
        """
        Generate proposal based on input.
        
        Implements A3 (Transparency) by making proposal explicit.
        """
        logger.info("Generating proposal...")
        
        input_text = state["input"]
        
        proposal_prompt = f"""{{PROPOSAL_SYSTEM_PROMPT}}

User request: {input_text}

Generate a proposal for how to fulfill this request. Be specific and clear.
"""
        
        response = self.llm.invoke(proposal_prompt)
        proposal = response.content
        
        logger.info(f"Proposal generated: {proposal[:100]}...")
        
        return {
            "proposal": proposal,
            "status": "proposing",
            "messages": state["messages"] + [
                AIMessage(content=f"Proposal: {proposal}")
            ]
        }
    
    def _route_after_proposal(self, state: {{GRAPH_CLASS_NAME}}State) -> str:
        """
        Route after proposal generation.
        
        Checks if approval is needed (A2 - User Primacy).
        """
        # Check if this requires approval
        requires_approval = self._check_approval_required(state["proposal"])
        
        if requires_approval and not self.auto_approve:
            return "request_approval"
        else:
            # Auto-approve or doesn't need approval
            return "finalize"
    
    def _check_approval_required(self, proposal: str) -> bool:
        """
        Check if proposal requires human approval (A2).
        
        Args:
            proposal: Generated proposal
        
        Returns:
            True if approval is needed
        """
        # Keywords that indicate approval is needed
        approval_keywords = [
            "delete", "remove", "modify", "change", "update",
            "create", "generate", "send", "publish", "execute"
        ]
        
        proposal_lower = proposal.lower()
        return any(keyword in proposal_lower for keyword in approval_keywords)
    
    def _request_approval_node(self, state: {{GRAPH_CLASS_NAME}}State) -> dict:
        """
        Request human approval.
        
        Implements A2 (User Primacy) by requiring explicit approval.
        """
        logger.info("Requesting human approval...")
        
        approval_message = f"""{{APPROVAL_MESSAGE}}

Proposal:
{state["proposal"]}

Please review and provide feedback. Respond with:
- "APPROVE" to approve
- "REJECT" to reject
- Or provide specific feedback for improvements
"""
        
        return {
            "status": "awaiting_approval",
            "messages": state["messages"] + [
                AIMessage(content=approval_message)
            ]
        }
    
    def _route_after_approval(self, state: {{GRAPH_CLASS_NAME}}State) -> str:
        """
        Route based on human feedback.
        
        Args:
            state: Current state
        
        Returns:
            Next node name
        """
        feedback = state.get("human_feedback", "").upper()
        
        if feedback == "APPROVE" or self.auto_approve:
            return "finalize"
        elif feedback == "REJECT":
            return "finalize"  # End with rejection
        else:
            # Has feedback to incorporate
            return "incorporate_feedback"
    
    def _incorporate_feedback_node(self, state: {{GRAPH_CLASS_NAME}}State) -> dict:
        """
        Incorporate human feedback into proposal.
        
        Implements A2 (User Primacy) by respecting user feedback.
        """
        logger.info("Incorporating feedback...")
        
        feedback = state.get("human_feedback", "")
        original_proposal = state["proposal"]
        
        feedback_prompt = f"""{{FEEDBACK_SYSTEM_PROMPT}}

Original proposal:
{original_proposal}

Human feedback:
{feedback}

Revise the proposal based on this feedback. Maintain the original intent while addressing the concerns.
"""
        
        response = self.llm.invoke(feedback_prompt)
        revised_proposal = response.content
        
        logger.info("Feedback incorporated")
        
        return {
            "proposal": revised_proposal,
            "status": "proposing",
            "messages": state["messages"] + [
                AIMessage(content=f"Revised proposal: {revised_proposal}")
            ]
        }
    
    def _finalize_node(self, state: {{GRAPH_CLASS_NAME}}State) -> dict:
        """
        Finalize output based on approval status.
        
        Implements A1 (Verifiability) by logging final state.
        """
        logger.info("Finalizing output...")
        
        if state.get("approved", False) or self.auto_approve:
            final_output = state["proposal"]
            status = "completed"
        else:
            final_output = "Proposal was not approved."
            status = "rejected"
        
        return {
            "final_output": final_output,
            "status": status,
            "messages": state["messages"] + [
                AIMessage(content=f"Final output: {final_output}")
            ]
        }
    
    def run(
        self,
        input_text: str,
        thread_id: Optional[str] = None
    ) -> {{GRAPH_CLASS_NAME}}State:
        """
        Run the workflow.
        
        Args:
            input_text: User input
            thread_id: Optional thread ID
        
        Returns:
            Workflow state
        """
        logger.info(f"Running workflow with input: {input_text[:100]}...")
        
        initial_state: {{GRAPH_CLASS_NAME}}State = {
            "messages": [HumanMessage(content=input_text)],
            "input": input_text,
            "proposal": None,
            "human_feedback": None,
            "approved": False,
            "final_output": None,
            "status": "proposing"
        }
        
        config = {}
        if thread_id:
            config = {"configurable": {"thread_id": thread_id}}
        
        result = self.app.invoke(initial_state, config)
        
        logger.info(f"Workflow status: {result['status']}")
        return result
    
    def approve(
        self,
        thread_id: str,
        feedback: str = "APPROVE"
    ) -> {{GRAPH_CLASS_NAME}}State:
        """
        Provide approval feedback.
        
        Args:
            thread_id: Thread ID
            feedback: Approval feedback
        
        Returns:
            Updated state
        """
        logger.info(f"Providing approval: {feedback[:50]}...")
        
        # Get current state
        config = {"configurable": {"thread_id": thread_id}}
        current_state = self.app.get_state(config)
        
        # Update with feedback
        updated_state = {
            "human_feedback": feedback,
            "approved": feedback.upper() == "APPROVE"
        }
        
        # Continue workflow
        result = self.app.invoke(updated_state, config)
        
        return result
    
    def visualize(self) -> str:
        """Generate Mermaid diagram."""
        return self.app.get_graph().draw_mermaid()


# Example usage
if __name__ == "__main__":
    # Create workflow
    workflow = {{GRAPH_CLASS_NAME}}(auto_approve=False)
    
    # Visualize
    print("Workflow Structure:")
    print(workflow.visualize())
    print()
    
    # Run
    result = workflow.run("{{EXAMPLE_INPUT}}")
    
    print(f"Status: {result['status']}")
    if result["status"] == "awaiting_approval":
        print(f"Proposal: {result['proposal']}")
        print("\nProvide approval:")
        # In real usage, get feedback from user
        # workflow.approve(thread_id, "APPROVE")
