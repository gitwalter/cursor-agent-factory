"""
{{AGENT_NAME}} - AutoGen Assistant Agent

Purpose: {{AGENT_PURPOSE}}
Author: {{AUTHOR}}
Date: {{DATE}}

Axiom Alignment:
- A2 (User Primacy): Assistant serves user intent
- A3 (Transparency): Agent behavior is explicit
"""

from typing import List, Optional, Dict, Any
from autogen import AssistantAgent
from autogen.agentchat.contrib.capabilities.teachable_agent import TeachableAgent
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class {{AGENT_CLASS_NAME}}:
    """
    {{AGENT_NAME}} - AutoGen Assistant Agent
    
    Implements an AI assistant agent that can:
    - Use tools to interact with external systems
    - Participate in multi-agent conversations
    - Learn from interactions (if TeachableAgent)
    
    Example:
        >>> agent = {{AGENT_CLASS_NAME}}()
        >>> response = agent.generate_reply(messages=[{"role": "user", "content": "Hello"}])
    """
    
    def __init__(
        self,
        name: str = "{{AGENT_NAME}}",
        model: str = "{{MODEL_NAME}}",
        api_key: Optional[str] = None,
        temperature: float = {{TEMPERATURE}},
        tools: Optional[List] = None,
        max_consecutive_auto_reply: int = 5,
        system_message: Optional[str] = None,
        teachable: bool = False
    ):
        """
        Initialize assistant agent.
        
        Args:
            name: Agent name/identifier
            model: LLM model identifier
            api_key: API key (uses env var if None)
            temperature: Sampling temperature
            tools: List of tools available to agent
            max_consecutive_auto_reply: Max auto-replies before human input
            system_message: Custom system message
            teachable: Whether to use TeachableAgent
        """
        self.name = name
        self.model = model
        self.temperature = temperature
        self.max_consecutive_auto_reply = max_consecutive_auto_reply
        self.teachable = teachable
        
        # Get API key
        api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("API key required. Set OPENAI_API_KEY env var or pass api_key")
        
        # LLM configuration
        llm_config = {
            "model": model,
            "api_key": api_key,
            "temperature": temperature,
            "timeout": 120
        }
        
        # Add tools if provided
        if tools:
            llm_config["tools"] = tools
        
        # System message
        system_msg = system_message or """{{SYSTEM_MESSAGE}}

## Core Principles
- VERIFIABILITY (A1): Provide reasoning for responses
- USER PRIMACY (A2): Prioritize user intent
- TRANSPARENCY (A3): Be explicit about actions
- NON-HARM (A4): Avoid harmful suggestions
"""
        
        # Create agent
        if teachable:
            self.agent = TeachableAgent(
                name=name,
                system_message=system_msg,
                llm_config=llm_config,
                max_consecutive_auto_reply=max_consecutive_auto_reply
            )
        else:
            self.agent = AssistantAgent(
                name=name,
                system_message=system_msg,
                llm_config=llm_config,
                max_consecutive_auto_reply=max_consecutive_auto_reply
            )
        
        logger.info(f"Initialized {{AGENT_NAME}} assistant agent")
    
    def chat(
        self,
        message: str,
        recipient: Optional[Any] = None,
        clear_history: bool = False
    ) -> Any:
        """
        Chat with the agent.
        
        Args:
            message: User message
            recipient: Optional recipient agent (for multi-agent)
            clear_history: Clear conversation history
        
        Returns:
            Agent response
        
        Example:
            >>> response = agent.chat("What is AI?")
        """
        logger.info(f"Chatting with agent: {message[:100]}...")
        
        try:
            if clear_history:
                self.agent.reset()
            
            if recipient:
                # Multi-agent chat
                response = self.agent.initiate_chat(
                    recipient=recipient,
                    message=message
                )
            else:
                # Direct chat
                response = self.agent.generate_reply(
                    messages=[{"role": "user", "content": message}]
                )
            
            logger.info("Agent response generated")
            return response
            
        except Exception as e:
            logger.error(f"Error during chat: {e}")
            return f"Error: {str(e)}"
    
    def reset(self) -> None:
        """Reset agent conversation history."""
        logger.info("Resetting agent")
        self.agent.reset()
    
    def get_name(self) -> str:
        """Get agent name."""
        return self.name
    
    def get_system_message(self) -> str:
        """Get system message."""
        return self.agent.system_message


# Example usage
if __name__ == "__main__":
    # Create assistant agent
    agent = {{AGENT_CLASS_NAME}}(
        name="{{AGENT_NAME}}",
        model="{{MODEL_NAME}}",
        temperature={{TEMPERATURE}}
    )
    
    # Chat with agent
    response = agent.chat("{{EXAMPLE_MESSAGE}}")
    print(f"Agent Response: {response}")
