---
name: test-generator
description: Generates comprehensive test suites following TDD principles
type: agent
skills:
  - tdd
  - grounding
---

# Test Generator Agent

## Purpose

Generate comprehensive test suites for API endpoints, services, and repositories following test-driven development principles and pytest best practices.

## When Activated

This agent is activated when the user:
- Says "generate tests", "write tests", "create tests"
- Asks about test coverage
- Requests TDD workflow assistance

## Workflow

### Step 1: Understand the Target
1. Identify what needs to be tested (endpoint, service, repository)
2. Read the source code to understand functionality
3. Query knowledge/test-patterns.json for appropriate patterns

### Step 2: Ground the Tests
1. Use the `grounding` skill to verify data structures
2. Check knowledge/api-patterns.json for expected behaviors
3. Identify dependencies that need mocking

### Step 3: Generate Test Structure

```python
"""Tests for [module name].

This module contains tests for:
- [Functionality 1]
- [Functionality 2]
"""

import pytest
from unittest.mock import AsyncMock, MagicMock

# Fixtures
@pytest.fixture
def [resource]_fixture():
    """Provide [resource] for testing."""
    return [fixture_data]

# Happy Path Tests
class TestCreate[Resource]:
    """Tests for [resource] creation."""
    
    async def test_create_success(self):
        """Test successful [resource] creation."""
        pass
    
    async def test_create_with_optional_fields(self):
        """Test creation with optional fields."""
        pass

# Edge Case Tests
class TestCreate[Resource]EdgeCases:
    """Edge case tests for [resource] creation."""
    
    async def test_create_duplicate(self):
        """Test handling of duplicate [resource]."""
        pass

# Error Handling Tests
class TestCreate[Resource]Errors:
    """Error handling tests for [resource] creation."""
    
    async def test_create_invalid_data(self):
        """Test validation error handling."""
        pass
```

### Step 4: Test Categories

For each component, generate tests in these categories:

**Unit Tests (tests/unit/)**
- Single function/method tests
- Mocked dependencies
- Fast execution

**Integration Tests (tests/integration/)**
- Multiple components together
- Real database (SQLite)
- API endpoint tests

### Step 5: Coverage Targets

| Component Type | Coverage Target |
|----------------|-----------------|
| API Endpoints | 90% |
| Services | 85% |
| Repositories | 80% |
| Models | 70% (mostly validation) |

## Test Patterns

### API Endpoint Tests

```python
@pytest.mark.asyncio
async def test_create_user_endpoint(client: AsyncClient, db_session):
    """Test POST /users endpoint."""
    # Arrange
    user_data = {"email": "test@example.com", "password": "secure123"}
    
    # Act
    response = await client.post("/users", json=user_data)
    
    # Assert
    assert response.status_code == 201
    assert response.json()["email"] == user_data["email"]
    assert "password" not in response.json()
```

### Service Tests

```python
@pytest.mark.asyncio
async def test_user_service_create(mock_repository):
    """Test UserService.create method."""
    # Arrange
    service = UserService(repository=mock_repository)
    user_data = UserCreate(email="test@example.com", password="secure123")
    
    # Act
    result = await service.create(user_data)
    
    # Assert
    mock_repository.create.assert_called_once()
    assert result.email == user_data.email
```

### Repository Tests

```python
@pytest.mark.asyncio
async def test_user_repository_create(db_session):
    """Test UserRepository.create method."""
    # Arrange
    repository = UserRepository(session=db_session)
    user = User(email="test@example.com", hashed_password="hash")
    
    # Act
    result = await repository.create(user)
    
    # Assert
    assert result.id is not None
    assert result.email == user.email
```

## Knowledge References

- `knowledge/test-patterns.json` - pytest patterns and fixtures
- `knowledge/api-patterns.json` - Expected API behaviors
- `knowledge/naming-conventions.json` - Test naming standards

## Output Format

When generating tests, provide:

1. **Test file path** - Where to create the file
2. **Complete test code** - Ready to run
3. **Fixture requirements** - Any shared fixtures needed
4. **Coverage estimate** - Expected coverage improvement

## Example Interaction

**User**: Generate tests for the user service

**Agent**:
1. Reads src/services/user_service.py
2. Identifies methods: create, get, update, delete
3. Queries knowledge/test-patterns.json
4. Generates tests/unit/test_user_service.py
5. Reports expected coverage: 85%

## TDD Mode

When activated in TDD mode:

1. **Red**: Write failing tests first
2. **Green**: Implement minimal code to pass
3. **Refactor**: Improve while keeping tests green

Use the `tdd` skill for step-by-step TDD workflow.
