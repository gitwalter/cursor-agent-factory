{
  "metadata": {
    "blueprintId": "python-fine-tuning",
    "blueprintName": "Python LLM Fine-Tuning Blueprint",
    "description": "LLM fine-tuning projects with PEFT, LoRA, and Hugging Face",
    "version": "1.0.0",
    "author": "Cursor Agent Factory",
    "tags": ["python", "fine-tuning", "llm", "lora", "peft", "huggingface"],
    "purpose": "Enable efficient fine-tuning of large language models for custom tasks"
  },
  "stack": {
    "primaryLanguage": "python",
    "frameworks": [
      {"name": "Transformers", "version": "4.40+", "purpose": "Model loading and training"},
      {"name": "PEFT", "version": "0.10+", "purpose": "Parameter-efficient fine-tuning"},
      {"name": "TRL", "version": "0.8+", "purpose": "SFT, DPO, ORPO trainers"},
      {"name": "Datasets", "version": "2.18+", "purpose": "Data loading"},
      {"name": "Accelerate", "version": "0.28+", "purpose": "Distributed training"},
      {"name": "BitsAndBytes", "version": "0.42+", "purpose": "Quantization"}
    ],
    "databases": [
      {"type": "tracking", "name": "MLflow", "purpose": "Experiment tracking"},
      {"type": "tracking", "name": "Weights & Biases", "purpose": "Visualization", "optional": true}
    ],
    "tools": [
      {"name": "pytest", "purpose": "Testing"},
      {"name": "ruff", "purpose": "Linting"},
      {"name": "huggingface-cli", "purpose": "Hub operations"},
      {"name": "lm-eval", "purpose": "Evaluation harness"}
    ]
  },
  "knowledge": [
    {"filename": "llm-fine-tuning-patterns.json", "description": "Fine-tuning patterns"},
    {"filename": "huggingface-patterns.json", "description": "HF Transformers patterns"},
    {"filename": "deep-learning-patterns.json", "description": "Training best practices"},
    {"filename": "llm-evaluation-patterns.json", "description": "Evaluation patterns"}
  ],
  "projectStructure": {
    "directories": [
      {"path": ".cursor/agents/", "purpose": "AI agent definitions"},
      {"path": "src/", "purpose": "Source code"},
      {"path": "src/data/", "purpose": "Data preparation"},
      {"path": "src/training/", "purpose": "Training scripts"},
      {"path": "src/evaluation/", "purpose": "Evaluation code"},
      {"path": "src/inference/", "purpose": "Inference code"},
      {"path": "configs/", "purpose": "Training configs"},
      {"path": "data/", "purpose": "Training data"},
      {"path": "data/raw/", "purpose": "Raw data"},
      {"path": "data/processed/", "purpose": "Formatted data"},
      {"path": "outputs/", "purpose": "Training outputs"},
      {"path": "adapters/", "purpose": "Saved LoRA adapters"},
      {"path": "merged/", "purpose": "Merged models"},
      {"path": "tests/", "purpose": "Test files"}
    ],
    "files": [
      {"path": ".cursorrules", "purpose": "Agent behavior rules"},
      {"path": "README.md", "purpose": "Project documentation"},
      {"path": "pyproject.toml", "purpose": "Python project config"},
      {"path": "requirements.txt", "purpose": "Dependencies"},
      {"path": "train.py", "purpose": "Main training script"},
      {"path": "evaluate.py", "purpose": "Evaluation script"},
      {"path": "merge.py", "purpose": "Merge LoRA script"},
      {"path": "Dockerfile", "purpose": "Container definition"}
    ]
  },
  "cursorrules": {
    "variables": [
      {"name": "HF_TOKEN", "description": "Hugging Face token"},
      {"name": "WANDB_API_KEY", "description": "W&B API key", "optional": true}
    ],
    "rules": [
      {"name": "Data Quality", "description": "Verify training data quality before training"},
      {"name": "LoRA First", "description": "Start with LoRA, try QLoRA if memory limited"},
      {"name": "Validation", "description": "Always use validation set"},
      {"name": "Checkpointing", "description": "Save checkpoints regularly"},
      {"name": "Evaluation", "description": "Evaluate before and after fine-tuning"}
    ]
  }
}
