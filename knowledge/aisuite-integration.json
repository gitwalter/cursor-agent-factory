{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "AISuite Integration Guide",
  "description": "Configuration and usage guide for Andrew Ng's aisuite - unified LLM interface with MCP support",
  "version": "1.0.0",
  "overview": {
    "name": "aisuite",
    "author": "Andrew Ng",
    "repository": "https://github.com/andrewyng/aisuite",
    "license": "MIT",
    "stars": "13.4k+",
    "type": "library",
    "languages": ["python", "javascript", "typescript"],
    "description": "Lightweight library providing unified API for 20+ LLM providers with built-in MCP client support"
  },
  "keyFeatures": [
    "Unified API across multiple LLM providers",
    "OpenAI-compatible interface for easy adoption",
    "Built-in agent support with max_turns parameter",
    "Native MCP client integration for tool calling",
    "Automatic tool execution and schema generation",
    "Support for 20+ providers: OpenAI, Anthropic, Google, AWS, Cohere, Mistral, Ollama, etc."
  ],
  "installation": {
    "python": {
      "base": "pip install aisuite",
      "withProvider": "pip install 'aisuite[anthropic]'",
      "all": "pip install 'aisuite[all]'",
      "withMcp": "pip install 'aisuite[mcp]'"
    },
    "javascript": {
      "base": "npm install aisuite"
    }
  },
  "providers": [
    {"id": "openai", "name": "OpenAI", "envVar": "OPENAI_API_KEY", "models": ["gpt-4o", "gpt-4", "gpt-3.5-turbo"]},
    {"id": "anthropic", "name": "Anthropic", "envVar": "ANTHROPIC_API_KEY", "models": ["claude-3-5-sonnet", "claude-3-opus", "claude-3-haiku"]},
    {"id": "google", "name": "Google", "envVar": "GOOGLE_API_KEY", "models": ["gemini-pro", "gemini-ultra"]},
    {"id": "aws", "name": "AWS Bedrock", "envVar": "AWS_ACCESS_KEY_ID", "models": ["anthropic.claude-3", "amazon.titan"]},
    {"id": "azure", "name": "Azure OpenAI", "envVar": "AZURE_OPENAI_API_KEY", "models": ["gpt-4", "gpt-35-turbo"]},
    {"id": "cohere", "name": "Cohere", "envVar": "COHERE_API_KEY", "models": ["command-r-plus", "command-r"]},
    {"id": "mistral", "name": "Mistral", "envVar": "MISTRAL_API_KEY", "models": ["mistral-large", "mistral-medium"]},
    {"id": "groq", "name": "Groq", "envVar": "GROQ_API_KEY", "models": ["llama3-70b", "mixtral-8x7b"]},
    {"id": "ollama", "name": "Ollama (Local)", "envVar": null, "models": ["llama3", "mistral", "codellama"]},
    {"id": "huggingface", "name": "Hugging Face", "envVar": "HF_TOKEN", "models": ["meta-llama/Llama-3"]},
    {"id": "fireworks", "name": "Fireworks AI", "envVar": "FIREWORKS_API_KEY", "models": ["llama-v3-70b"]},
    {"id": "together", "name": "Together AI", "envVar": "TOGETHER_API_KEY", "models": ["meta-llama/Llama-3"]}
  ],
  "basicUsage": {
    "python": "import aisuite as ai\n\nclient = ai.Client()\n\nresponse = client.chat.completions.create(\n    model=\"openai:gpt-4o\",  # Format: provider:model\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ],\n    temperature=0.7\n)\n\nprint(response.choices[0].message.content)",
    "multiProvider": "# Same code works across providers\nmodels = [\n    \"openai:gpt-4o\",\n    \"anthropic:claude-3-5-sonnet-20240620\",\n    \"google:gemini-pro\"\n]\n\nfor model in models:\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages\n    )\n    print(f\"{model}: {response.choices[0].message.content}\")"
  },
  "mcpIntegration": {
    "description": "AISuite can consume MCP servers as tools for agentic workflows",
    "configDictFormat": "# Option 1: Config dict (simple use cases)\nresponse = client.chat.completions.create(\n    model=\"openai:gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"List files in current directory\"}],\n    tools=[{\n        \"type\": \"mcp\",\n        \"name\": \"filesystem\",\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/dir\"]\n    }],\n    max_turns=3\n)",
    "mcpClientFormat": "# Option 2: MCPClient (advanced use cases)\nfrom aisuite.mcp import MCPClient\n\nmcp = MCPClient(\n    command=\"npx\",\n    args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/dir\"]\n)\n\nresponse = client.chat.completions.create(\n    model=\"openai:gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"List files\"}],\n    tools=mcp.get_callable_tools(),\n    max_turns=3\n)\n\nmcp.close()  # Clean up"
  },
  "agenticWorkflows": {
    "description": "Use max_turns for automatic tool execution loops",
    "example": "def get_weather(location: str) -> str:\n    \"\"\"Get weather for a location.\"\"\"\n    return f\"Sunny, 72Â°F in {location}\"\n\nresponse = client.chat.completions.create(\n    model=\"openai:gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"What's the weather in NYC?\"}],\n    tools=[get_weather],  # Pass Python functions directly\n    max_turns=3  # Automatic tool execution\n)\n\n# Access intermediate messages\nprint(response.choices[0].intermediate_messages)"
  },
  "factoryIntegration": {
    "recommendation": "Add aisuite as optional dependency for projects requiring multi-provider LLM access",
    "useCases": [
      "Comparing responses across LLM providers",
      "Failover between providers",
      "Using different models for different tasks",
      "Local development with Ollama, production with cloud providers"
    ],
    "configurationTemplate": {
      "name": "aisuite",
      "type": "library",
      "installation": "pip install 'aisuite[all,mcp]'",
      "envFile": ".env.aisuite",
      "envVariables": [
        "OPENAI_API_KEY",
        "ANTHROPIC_API_KEY",
        "GOOGLE_API_KEY"
      ]
    }
  },
  "setupSteps": [
    "Install aisuite: pip install 'aisuite[all]' (or with specific providers)",
    "Set environment variables for desired providers",
    "For MCP support: pip install 'aisuite[mcp]'",
    "Import and create client: import aisuite as ai; client = ai.Client()",
    "Use model format: provider:model-name"
  ],
  "documentation": {
    "github": "https://github.com/andrewyng/aisuite",
    "examples": "https://github.com/andrewyng/aisuite/tree/main/examples",
    "guides": "https://github.com/andrewyng/aisuite/tree/main/guides",
    "mcpDocs": "https://github.com/andrewyng/aisuite/blob/main/docs/mcp-tools.md"
  }
}
