{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "CrewAI Patterns",
  "description": "Best practices and patterns for CrewAI 0.50+ multi-agent systems",
  "version": "1.0.0",
  "axiomAlignment": {
    "A2_user_primacy": "Crews ensure user goals are achieved through coordinated agent effort",
    "A3_transparency": "Agent roles and tasks are explicit and traceable"
  },
  "agent_patterns": {
    "agent_definition": {
      "description": "Define agents with role, goal, and backstory",
      "use_when": "Creating specialized agents for specific tasks",
      "code_example": "from crewai import Agent\nfrom crewai_tools import SerperDevTool\n\nresearcher = Agent(\n    role='Research Analyst',\n    goal='Conduct thorough research on given topics and provide accurate information',\n    backstory='''You are an experienced research analyst with a keen eye for detail.\n    You excel at finding reliable sources and synthesizing complex information\n    into clear, actionable insights.''',\n    verbose=True,\n    allow_delegation=False,\n    tools=[SerperDevTool()],\n    max_iter=3,\n    memory=True\n)",
      "best_practices": [
        "Define clear, specific roles",
        "Write detailed backstories that guide behavior",
        "Set appropriate max_iter to prevent infinite loops",
        "Use memory=True for context retention",
        "Choose tools relevant to agent's role"
      ],
      "key_properties": {
        "role": "Agent's job title/function",
        "goal": "What the agent should accomplish",
        "backstory": "Context that shapes agent behavior",
        "verbose": "Enable detailed logging",
        "allow_delegation": "Can agent delegate to others",
        "tools": "List of tools agent can use",
        "max_iter": "Maximum iterations per task",
        "memory": "Enable conversation memory"
      }
    },
    "agent_with_custom_llm": {
      "description": "Configure agent with specific LLM",
      "use_when": "Need different models for different agents",
      "code_example": "from crewai import Agent, LLM\nfrom langchain_openai import ChatOpenAI\n\n# Custom LLM configuration\nfast_llm = LLM(\n    model=ChatOpenAI(\n        model='gpt-3.5-turbo',\n        temperature=0.7\n    )\n)\n\nresearcher = Agent(\n    role='Researcher',\n    goal='Research topics quickly',\n    backstory='Fast researcher',\n    llm=fast_llm\n)",
      "best_practices": [
        "Use faster models for simple tasks",
        "Use more capable models for complex reasoning",
        "Consider cost vs capability trade-offs"
      ]
    },
    "agent_with_function_calling": {
      "description": "Agent with custom function tools",
      "use_when": "Need custom business logic as tools",
      "code_example": "from crewai import Agent\nfrom crewai_tools import tool\nfrom typing import Type\nfrom pydantic import BaseModel, Field\n\nclass SearchInput(BaseModel):\n    query: str = Field(description='Search query')\n    max_results: int = Field(default=5, ge=1, le=20)\n\n@tool('search_database')\ndef search_database(query: str, max_results: int) -> str:\n    '''Search internal database for information.'''\n    # Implementation here\n    return f'Found {max_results} results for {query}'\n\nresearcher = Agent(\n    role='Database Researcher',\n    goal='Find information in database',\n    backstory='Expert at querying databases',\n    tools=[search_database]\n)",
      "best_practices": [
        "Use @tool decorator for custom tools",
        "Define Pydantic schemas for tool inputs",
        "Provide clear tool descriptions",
        "Handle errors in tool implementations"
      ]
    }
  },
  "task_patterns": {
    "task_definition": {
      "description": "Define tasks with description, agent assignment, and expected output",
      "use_when": "Breaking down work into discrete tasks",
      "code_example": "from crewai import Task\n\nresearch_task = Task(\n    description='''Research the latest developments in AI agent frameworks.\n    Focus on LangChain, CrewAI, and AutoGen. Provide a comprehensive\n    comparison of their features and use cases.''',\n    agent=researcher,\n    expected_output='''A detailed report with:\n    1. Overview of each framework\n    2. Key features comparison\n    3. Use case recommendations\n    4. Pros and cons of each'''\n)",
      "best_practices": [
        "Write clear, specific task descriptions",
        "Define expected_output format",
        "Assign tasks to appropriate agents",
        "Set dependencies when tasks must run sequentially"
      ],
      "key_properties": {
        "description": "What needs to be done",
        "agent": "Agent responsible for task",
        "expected_output": "Format and content of output",
        "async_execution": "Run task asynchronously",
        "output_file": "Save output to file",
        "context": "Additional context for task"
      }
    },
    "task_with_dependencies": {
      "description": "Tasks that depend on other tasks",
      "use_when": "Sequential workflow where one task needs another's output",
      "code_example": "research_task = Task(\n    description='Research topic X',\n    agent=researcher,\n    expected_output='Research report'\n)\n\nwrite_task = Task(\n    description='Write article based on research',\n    agent=writer,\n    expected_output='Article draft',\n    context=[research_task]\n)\n\nreview_task = Task(\n    description='Review and edit article',\n    agent=reviewer,\n    expected_output='Final article',\n    context=[write_task]\n)",
      "best_practices": [
        "Use context parameter for dependencies",
        "Ensure dependency order is correct",
        "Test with different dependency chains"
      ]
    },
    "task_with_human_input": {
      "description": "Task that requires human approval or input",
      "use_when": "Critical decisions need human oversight",
      "code_example": "approval_task = Task(\n    description='Review proposal and approve or request changes',\n    agent=manager,\n    expected_output='Approval decision with feedback',\n    human_input=True\n)",
      "best_practices": [
        "Use human_input for critical tasks",
        "Provide clear context for human decision",
        "Set timeouts for human responses"
      ],
      "axiom_alignment": "A2 (User Primacy) - Human oversight for critical decisions"
    },
    "async_task": {
      "description": "Execute task asynchronously",
      "use_when": "Task can run independently",
      "code_example": "parallel_task = Task(\n    description='Process data independently',\n    agent=processor,\n    expected_output='Processed data',\n    async_execution=True\n)",
      "best_practices": [
        "Use for independent tasks",
        "Consider resource limits",
        "Monitor async task completion"
      ]
    }
  },
  "crew_patterns": {
    "basic_crew": {
      "description": "Simple crew with agents and tasks",
      "use_when": "Straightforward multi-agent workflow",
      "code_example": "from crewai import Crew, Process\n\ncrew = Crew(\n    agents=[researcher, writer, reviewer],\n    tasks=[research_task, write_task, review_task],\n    process=Process.sequential,\n    verbose=True\n)\n\nresult = crew.kickoff()",
      "best_practices": [
        "Start with sequential process",
        "Enable verbose for debugging",
        "Test with simple tasks first"
      ]
    },
    "hierarchical_crew": {
      "description": "Crew with manager agent overseeing workers",
      "use_when": "Need centralized coordination and decision-making",
      "code_example": "manager = Agent(\n    role='Project Manager',\n    goal='Coordinate team and ensure quality deliverables',\n    backstory='Experienced manager who delegates effectively',\n    allow_delegation=True,\n    verbose=True\n)\n\ncrew = Crew(\n    agents=[manager, researcher, writer, reviewer],\n    tasks=[research_task, write_task, review_task],\n    process=Process.hierarchical,\n    manager_llm=ChatOpenAI(model='gpt-4'),\n    verbose=True\n)",
      "best_practices": [
        "Manager should have allow_delegation=True",
        "Use capable LLM for manager",
        "Define clear delegation rules",
        "Monitor manager decisions"
      ]
    },
    "consensual_crew": {
      "description": "Crew where agents collaborate and reach consensus",
      "use_when": "Tasks benefit from multiple perspectives",
      "code_example": "crew = Crew(\n    agents=[researcher, writer, reviewer],\n    tasks=[research_task, write_task, review_task],\n    process=Process.consensual,\n    verbose=True\n)",
      "best_practices": [
        "Use for creative or complex tasks",
        "Ensure agents have complementary skills",
        "Set iteration limits to prevent deadlock"
      ]
    },
    "crew_with_custom_llm": {
      "description": "Configure crew with specific LLM",
      "use_when": "Need consistent model across crew",
      "code_example": "from crewai import LLM\n\ncrew_llm = LLM(\n    model=ChatOpenAI(\n        model='gpt-4',\n        temperature=0.7\n    )\n)\n\ncrew = Crew(\n    agents=[researcher, writer],\n    tasks=[research_task, write_task],\n    llm=crew_llm,\n    verbose=True\n)",
      "best_practices": [
        "Use consistent LLM for reproducible results",
        "Consider cost implications",
        "Test with different temperature settings"
      ]
    }
  },
  "process_types": {
    "sequential": {
      "description": "Tasks execute one after another",
      "use_when": "Tasks have clear dependencies",
      "code_example": "crew = Crew(\n    agents=[agent1, agent2, agent3],\n    tasks=[task1, task2, task3],\n    process=Process.sequential\n)",
      "best_practices": [
        "Order tasks by dependencies",
        "Use for linear workflows",
        "Monitor task completion"
      ]
    },
    "hierarchical": {
      "description": "Manager agent coordinates worker agents",
      "use_when": "Need centralized control and delegation",
      "code_example": "crew = Crew(\n    agents=[manager, worker1, worker2],\n    tasks=[task1, task2],\n    process=Process.hierarchical,\n    manager_llm=ChatOpenAI(model='gpt-4')\n)",
      "best_practices": [
        "Manager must have allow_delegation=True",
        "Use capable LLM for manager",
        "Define clear delegation criteria",
        "Monitor manager decisions"
      ]
    },
    "consensual": {
      "description": "Agents collaborate and reach consensus",
      "use_when": "Multiple perspectives improve quality",
      "code_example": "crew = Crew(\n    agents=[agent1, agent2, agent3],\n    tasks=[task1, task2],\n    process=Process.consensual\n)",
      "best_practices": [
        "Set iteration limits",
        "Define consensus criteria",
        "Monitor for deadlocks"
      ]
    }
  },
  "memory_patterns": {
    "agent_memory": {
      "description": "Enable memory for individual agents",
      "use_when": "Agent needs to remember past interactions",
      "code_example": "researcher = Agent(\n    role='Researcher',\n    goal='Research topics',\n    backstory='Experienced researcher',\n    memory=True,\n    max_iter=3\n)",
      "best_practices": [
        "Use memory for conversational agents",
        "Monitor memory usage",
        "Consider memory limits"
      ]
    },
    "crew_memory": {
      "description": "Shared memory across crew",
      "use_when": "Agents need to share context",
      "code_example": "crew = Crew(\n    agents=[agent1, agent2],\n    tasks=[task1, task2],\n    memory=True,\n    verbose=True\n)",
      "best_practices": [
        "Use for collaborative tasks",
        "Monitor shared memory size",
        "Clear memory between runs if needed"
      ]
    }
  },
  "tool_integration": {
    "builtin_tools": {
      "description": "Use CrewAI built-in tools",
      "code_example": "from crewai_tools import (\n    SerperDevTool,\n    WebsiteSearchTool,\n    FileReadTool,\n    DirectoryReadTool\n)\n\nresearcher = Agent(\n    role='Researcher',\n    goal='Research topics',\n    backstory='Expert researcher',\n    tools=[\n        SerperDevTool(),\n        WebsiteSearchTool(),\n        FileReadTool(),\n        DirectoryReadTool()\n    ]\n)",
      "best_practices": [
        "Choose tools relevant to agent role",
        "Configure tool parameters appropriately",
        "Handle tool failures gracefully"
      ]
    },
    "custom_tools": {
      "description": "Create custom tools for agents",
      "code_example": "from crewai_tools import tool\nfrom typing import Type\nfrom pydantic import BaseModel, Field\n\nclass QueryInput(BaseModel):\n    query: str = Field(description='Database query')\n    limit: int = Field(default=10, ge=1, le=100)\n\n@tool('query_database')\ndef query_database(query: str, limit: int) -> str:\n    '''Execute database query and return results.'''\n    try:\n        results = execute_query(query, limit)\n        return json.dumps(results, indent=2)\n    except Exception as e:\n        return f'Error: {str(e)}'\n\nagent = Agent(\n    role='Data Analyst',\n    goal='Analyze data',\n    backstory='Expert data analyst',\n    tools=[query_database]\n)",
      "best_practices": [
        "Use @tool decorator",
        "Define Pydantic input schemas",
        "Provide clear descriptions",
        "Handle errors gracefully",
        "Return structured outputs"
      ]
    }
  },
  "peer_review_patterns": {
    "review_task": {
      "description": "Task where agent reviews another agent's work",
      "use_when": "Quality assurance is critical",
      "code_example": "write_task = Task(\n    description='Write article',\n    agent=writer,\n    expected_output='Article draft'\n)\n\nreview_task = Task(\n    description='''Review the article draft for:\n    1. Accuracy and fact-checking\n    2. Grammar and style\n    3. Clarity and readability\n    Provide detailed feedback.''',\n    agent=reviewer,\n    expected_output='Review feedback with recommendations',\n    context=[write_task]\n)",
      "best_practices": [
        "Define clear review criteria",
        "Use context to pass reviewed work",
        "Specify expected output format"
      ]
    },
    "iterative_review": {
      "description": "Multiple review cycles",
      "use_when": "Need multiple rounds of improvement",
      "code_example": "write_task = Task(description='Write article', agent=writer, expected_output='Draft')\nreview_task = Task(description='Review article', agent=reviewer, expected_output='Feedback', context=[write_task])\nrevise_task = Task(description='Revise based on feedback', agent=writer, expected_output='Revised draft', context=[review_task])\nfinal_review_task = Task(description='Final review', agent=reviewer, expected_output='Approval', context=[revise_task])",
      "best_practices": [
        "Limit review cycles",
        "Track improvements",
        "Define exit criteria"
      ]
    }
  },
  "manager_agent_patterns": {
    "delegation_manager": {
      "description": "Manager that delegates tasks to workers",
      "use_when": "Need intelligent task routing",
      "code_example": "manager = Agent(\n    role='Project Manager',\n    goal='Coordinate team and ensure quality',\n    backstory='''You are an experienced project manager who excels at\n    breaking down complex projects into tasks and assigning them to\n    the right team members. You monitor progress and ensure deliverables\n    meet quality standards.''',\n    allow_delegation=True,\n    verbose=True,\n    max_iter=5\n)\n\ncrew = Crew(\n    agents=[manager, researcher, writer, reviewer],\n    tasks=[complex_task],\n    process=Process.hierarchical,\n    manager_llm=ChatOpenAI(model='gpt-4', temperature=0.3)\n)",
      "best_practices": [
        "Write detailed backstory for delegation logic",
        "Use capable LLM for manager",
        "Set appropriate max_iter",
        "Monitor delegation decisions",
        "Define clear task descriptions"
      ]
    },
    "quality_manager": {
      "description": "Manager focused on quality assurance",
      "use_when": "Quality is paramount",
      "code_example": "quality_manager = Agent(\n    role='Quality Assurance Manager',\n    goal='Ensure all deliverables meet high quality standards',\n    backstory='''You are a meticulous QA manager who reviews all work\n    before approval. You check for accuracy, completeness, and adherence\n    to requirements.''',\n    allow_delegation=True,\n    verbose=True\n)",
      "best_practices": [
        "Define quality criteria clearly",
        "Use detailed review prompts",
        "Track quality metrics"
      ]
    }
  },
  "output_handling": {
    "save_to_file": {
      "description": "Save task output to file",
      "code_example": "task = Task(\n    description='Generate report',\n    agent=writer,\n    expected_output='Report in markdown format',\n    output_file='report.md'\n)",
      "best_practices": [
        "Specify file format in expected_output",
        "Use appropriate file extensions",
        "Handle file write errors"
      ]
    },
    "structured_output": {
      "description": "Get structured output from crew",
      "code_example": "result = crew.kickoff()\n\n# Access individual task outputs\nresearch_output = result.tasks_output[0]\nwrite_output = result.tasks_output[1]\n\n# Access final output\nfinal_output = result.raw",
      "best_practices": [
        "Parse outputs based on expected_output format",
        "Handle missing outputs gracefully",
        "Validate output structure"
      ]
    }
  },
  "best_practices": {
    "agent_design": [
      "Define clear, specific roles",
      "Write detailed backstories",
      "Choose appropriate tools",
      "Set max_iter to prevent loops",
      "Enable memory when needed"
    ],
    "task_design": [
      "Write clear task descriptions",
      "Define expected_output format",
      "Set dependencies correctly",
      "Use human_input for critical decisions"
    ],
    "crew_design": [
      "Start with sequential process",
      "Use hierarchical for complex coordination",
      "Enable verbose for debugging",
      "Test with simple tasks first"
    ],
    "performance": [
      "Use async_execution for independent tasks",
      "Choose appropriate LLM for each agent",
      "Monitor token usage",
      "Cache results when possible"
    ]
  },
  "anti_patterns": {
    "vague_roles": {
      "description": "Unclear agent roles",
      "problem": "Agents don't know what to do",
      "solution": "Define specific, actionable roles"
    },
    "missing_dependencies": {
      "description": "Tasks without proper dependencies",
      "problem": "Tasks execute in wrong order",
      "solution": "Use context parameter for dependencies"
    },
    "infinite_loops": {
      "description": "No max_iter limits",
      "problem": "Agents run indefinitely",
      "solution": "Set appropriate max_iter for all agents"
    },
    "tool_overload": {
      "description": "Too many tools per agent",
      "problem": "Confusion, poor tool selection",
      "solution": "Limit tools to 3-5 per agent, make them specific"
    }
  },
  "testing_patterns": {
    "unit_testing": {
      "description": "Test individual agents and tasks",
      "code_example": "def test_researcher_agent():\n    researcher = Agent(\n        role='Researcher',\n        goal='Research topics',\n        backstory='Test researcher'\n    )\n    \n    task = Task(\n        description='Research AI frameworks',\n        agent=researcher,\n        expected_output='Research report'\n    )\n    \n    result = task.execute()\n    assert 'framework' in result.lower()",
      "best_practices": [
        "Test agents independently",
        "Mock external tools",
        "Use deterministic LLM responses"
      ]
    },
    "integration_testing": {
      "description": "Test complete crew workflows",
      "code_example": "def test_research_crew():\n    crew = Crew(\n        agents=[researcher, writer],\n        tasks=[research_task, write_task],\n        process=Process.sequential\n    )\n    \n    result = crew.kickoff()\n    assert result.tasks_output is not None",
      "best_practices": [
        "Test with representative scenarios",
        "Verify task dependencies",
        "Check output formats"
      ]
    }
  }
}
