# Cursor Agent Factory - Continuous Integration Pipeline
#
# This workflow uses intelligent test packaging for fast error detection:
# 1. Fast tests first (unit + validation) - quick feedback
# 2. Slow tests with parallelization - catch integration issues
# 3. Fail-fast strategy for rapid error identification

name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  # Stage 1: Fast tests for quick feedback (< 30 seconds)
  fast-tests:
    name: Fast Tests (Unit + Validation)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run fast tests (unit + validation)
        run: |
          python -m pytest tests/unit/ tests/validation/ -v --tb=short -x
        # -x = fail fast on first error for quick feedback

  # Stage 2: Integration tests with parallelization
  integration-tests:
    name: Integration Tests
    needs: fast-tests  # Only run if fast tests pass
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: true  # Stop other matrix jobs on first failure
      matrix:
        os: [ubuntu-latest, windows-latest]
        python-version: ['3.10', '3.11', '3.12']

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run medium-speed integration tests (parallel)
        run: |
          python -m pytest tests/integration/ -v --tb=short -x -m "not slow" -n auto
        # -n auto = parallel execution using all CPU cores
        # -m "not slow" = skip quickstart tests in this phase

      - name: Run slow tests (quickstart) - sequential
        run: |
          python -m pytest tests/integration/ -v --tb=short -x -m "slow"
        # Slow tests run sequentially to avoid resource contention

  # Stage 3: Full coverage (only on main branch success)
  coverage:
    name: Coverage Report
    needs: integration-tests
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run all tests with coverage
        run: |
          python -m pytest tests/ --cov=scripts --cov=cli --cov-report=xml --cov-report=term-missing -n auto

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          fail_ci_if_error: false
          verbose: true

  # Parallel job: Lint (runs alongside fast-tests)
  lint:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install ruff

      - name: Run Ruff linter
        run: |
          ruff check scripts/ cli/ tests/ --output-format=github
        continue-on-error: true

  # Parallel job: Validate JSON (runs alongside fast-tests)
  validate-json:
    name: Validate JSON Files
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Validate JSON syntax
        run: |
          python -c "
          import json
          import sys
          from pathlib import Path
          
          errors = []
          for pattern in ['blueprints/**/*.json', 'patterns/**/*.json', 'knowledge/*.json']:
              for file in Path('.').glob(pattern):
                  try:
                      json.loads(file.read_text(encoding='utf-8'))
                  except json.JSONDecodeError as e:
                      errors.append(f'{file}: {e}')
          
          if errors:
              print('JSON validation errors:')
              for err in errors:
                  print(f'  - {err}')
              sys.exit(1)
          else:
              print('All JSON files are valid')
          "

  # Parallel job: Validate README (runs alongside fast-tests)
  validate-readme:
    name: Validate README Structure
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Validate README project structure
        run: |
          python scripts/validate_readme_structure.py --check

  # Final stage: Smoke test generation (after all tests pass)
  generate-test:
    name: Test Project Generation
    runs-on: ubuntu-latest
    needs: [integration-tests, validate-json]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Test blueprint generation
        run: |
          python cli/factory_cli.py --list-blueprints
          python cli/factory_cli.py --blueprint python-fastapi --output /tmp/test-project
          
          # Verify generated files exist
          test -f /tmp/test-project/.cursorrules
          test -f /tmp/test-project/README.md
          test -d /tmp/test-project/.cursor/agents
          test -d /tmp/test-project/.cursor/skills
          
          echo "Project generation successful!"
